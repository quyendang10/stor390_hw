---
title: "HW 2 Student"
author: "Quyen Dang"
date: "9/26/2024"
output: 
  html_document:
    number_sections: true
---

This homework is meant to illustrate the methods of classification algorithms as well as their potential pitfalls.  In class, we demonstrated K-Nearest-Neighbors using the `iris` dataset.  Today I will give you a different subset of this same data, and you will train a KNN classifier.  

```{r}
set.seed(123)
library(class)

df <- data(iris) 

normal <-function(x) {
  (x -min(x))/(max(x)-min(x))   
}

iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], normal))

subset <- c(1:45, 58, 60:70, 82, 94, 110:150)
iris_train <- iris_norm[subset,] 
iris_test <- iris_norm[-subset,] 

iris_target_category <- iris[subset,5]
iris_test_category <- iris[-subset,5]


```

#
Above, I have given you a training-testing partition.  Train the KNN with $K = 5$ on the training data and use this to classify the 50 test observations.  Once you have classified the test observations, create a contingency table -- like we did in class -- to evaluate which observations your algorithm is misclassifying.   

```{r}
set.seed(123)

pr <- knn(iris_train, iris_test, cl = iris_target_category, k = 5)

tab <- table(pr, iris_test_category)
tab

accuracy <- function(x){
  sum(diag(x)/(sum(rowSums(x)))) * 100
}

acc <- accuracy(tab)
acc
```

#

Discuss your results.  If you have done this correctly, you should have a classification error rate that is roughly 20% higher than what we observed in class.  Why is this the case? In particular run a summary of the `iris_test_category` as well as `iris_target_category` and discuss how this plays a role in your answer.  

The classifier correctly identified all setosa instances. For versicolor, 25 were correctly classified, but 11 virginica were misclassified as versicolor. For virginica, 9 were correctly classified. The KNN classifier resulted in an accuracy of 78%, with a classification error rate of 22%. The training set has 45 setosa, 14 versicolor, and 41 virginica, while the test set has 5 setosa, 36 versicolor, and 9 virginica. The small sample size of versicolor in the training set leads to higher misclassification of versicolor. The same applies for setosa and virginica, with high representation in the training set and little representation in the test set. As a result, the error rate is 22%, higher than the dataset in class.

```{r}
summary(iris_test_category)
summary(iris_target_category)
```

#

Choice of $K$ can also influence this classifier.  Why would choosing $K = 6$ not be advisable for this data? 

Choosing K = 6 isn't advisable because the KNN classifier works best with odd values of K when working with a three category problem. Using an even K increases the chance of ties in the voting process for nearest neighbors, leading to less accurate classifications.

#

Build a github repository to store your homework assignments.  Share the link in this file.  

https://github.com/quyendang10/stor390_hw
